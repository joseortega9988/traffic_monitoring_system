{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy in c:\\users\\j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: tabulate in c:\\users\\j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python numpy tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tabulate\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the value, the bigger a moving object should be to be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimun_area_contour = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    \"\"\"\n",
    "    Tracks objects in a video stream.\n",
    "    \"\"\"\n",
    "    class TrackingObject:\n",
    "        \"\"\"\n",
    "        Represents a tracked object.\n",
    "        \"\"\"\n",
    "        def __init__(self, initial_contour, tracking_id, ttl) -> None:\n",
    "            \"\"\"\n",
    "            Initializes a tracked object with its initial state.\n",
    "\n",
    "            initial_contour: The contour of the object in the initial frame.\n",
    "            tracking_id: A unique identifier for the object.\n",
    "            ttl: Time-to-live, the number of frames until the object is considered lost.\n",
    "            \"\"\"\n",
    "            self.tracking_id = tracking_id\n",
    "            self.ttl = ttl\n",
    "            self.location_history = []\n",
    "            self.centroid = Tracker.calculate_centroid(initial_contour)\n",
    "            self.updated = True\n",
    "\n",
    "            # Set up the Kalman filter for location prediction\n",
    "            filter_2d_kalman = cv2.KalmanFilter(4, 2)\n",
    "            filter_2d_kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "            filter_2d_kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "            filter_2d_kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 1e-4\n",
    "            self.filter_2d_kalman = filter_2d_kalman\n",
    "\n",
    "        def status_update_reset(self):\n",
    "            \"\"\"\n",
    "            Marks the object as not updated.\n",
    "            \"\"\"\n",
    "            self.updated = False\n",
    "\n",
    "        def contour_update(self, contour):\n",
    "            \"\"\"\n",
    "            Updates the object's location based on a new contour.\n",
    "            \"\"\"\n",
    "            self.updated = True\n",
    "            self.location_history.append(self.centroid)\n",
    "            self.centroid = Tracker.calculate_centroid(contour)\n",
    "\n",
    "            # Input the new location into the Kalman filter for future predictions\n",
    "            self.filter_2d_kalman.predict()\n",
    "            self.filter_2d_kalman.correct(np.array([[np.float32(self.centroid[0])], [np.float32(self.centroid[1])]]))\n",
    "        \n",
    "        def filter_kalman_update(self):\n",
    "            \"\"\"\n",
    "            Updates the object's location based on the Kalman filter's prediction.\n",
    "            \"\"\"\n",
    "            if len(self.location_history) < 5:\n",
    "                return\n",
    "\n",
    "            kalman_prediction = self.filter_2d_kalman.predict()\n",
    "            self.centroid = (int(kalman_prediction[0]), int(kalman_prediction[1]))\n",
    "            self.location_history.append(self.centroid)\n",
    "\n",
    "        def x_axis_direction(self) -> float:\n",
    "            \"\"\"\n",
    "            Determines the horizontal movement direction of the object.\n",
    "            \"\"\"\n",
    "            if len(self.location_history) < 5:\n",
    "                return 0\n",
    "\n",
    "            x_values = np.array(self.location_history)[:, 0]\n",
    "            measure_of_time = np.arange(len(x_values))\n",
    "    \n",
    "            # Linear regression to determine movement direction\n",
    "            contour_slope, _ = np.polyfit(measure_of_time, x_values, 1)\n",
    "    \n",
    "            return contour_slope\n",
    "\n",
    "    def __init__(self, proximity_threshold = 20, object_ttl = 10) -> None:\n",
    "        self.objects = []\n",
    "        self.last_tracking_id = 0\n",
    "        self.proximity_threshold = proximity_threshold\n",
    "        self.object_ttl = object_ttl\n",
    "        self.onObjectRemoved = None\n",
    "\n",
    "    @classmethod\n",
    "    def calculate_centroid(cls, contour):\n",
    "        \"\"\"\n",
    "        Computes the center point of a contour.\n",
    "        \"\"\"\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] == 0:\n",
    "            return None\n",
    "\n",
    "        centroid_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        centroid_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "        return (centroid_x, centroid_y)\n",
    "\n",
    "    def update(self, video_contours):\n",
    "        \"\"\"\n",
    "        Processes a new set of contours to update tracked objects.\n",
    "        \"\"\"\n",
    "        contours_originals = video_contours.copy()\n",
    "        video_contours = video_contours.copy()\n",
    "\n",
    "        # Mark all objects as not updated\n",
    "        [obj.status_update_reset() for obj in self.objects]\n",
    "\n",
    "        # Match contours with existing tracked objects\n",
    "        for i, contour in enumerate(video_contours):\n",
    "            centroid_point = Tracker.calculate_centroid(contour)\n",
    "\n",
    "            if centroid_point is None:\n",
    "                continue\n",
    "\n",
    "            nearest_object = None\n",
    "            nearest_distance = float('inf')\n",
    "            for obj in self.objects:\n",
    "                distance_measure = np.linalg.norm(np.array(obj.centroid) - np.array(centroid_point))\n",
    "                if distance_measure < nearest_distance:\n",
    "                    nearest_object = obj\n",
    "                    nearest_distance = distance_measure\n",
    "\n",
    "            if nearest_distance < self.proximity_threshold:\n",
    "                nearest_object.contour_update(contour)\n",
    "                video_contours[i] = None\n",
    "\n",
    "        # Introduce new objects for unmatched contours\n",
    "        for contour in video_contours:\n",
    "            if contour is None:\n",
    "                continue\n",
    "\n",
    "            for object in self.objects:\n",
    "                if cv2.pointPolygonTest(contour, object.centroid, False) > 0:\n",
    "                    break\n",
    "            else:\n",
    "                self.last_tracking_id += 1\n",
    "                self.objects.append(Tracker.TrackingObject(contour, self.last_tracking_id, self.object_ttl))\n",
    "\n",
    "        # Predict the location for objects not updated\n",
    "        [obj.filter_kalman_update() for obj in self.objects if not obj.updated]\n",
    "\n",
    "        # Clean up lost objects\n",
    "        for obj in self.objects:\n",
    "            for contour in contours_originals:\n",
    "                if cv2.pointPolygonTest(contour, obj.centroid, False) > 0:\n",
    "                    break\n",
    "            else:\n",
    "                obj.ttl -= 1\n",
    "\n",
    "                if obj.ttl <= 0:\n",
    "                    self.objects.remove(obj)\n",
    "\n",
    "                    if self.onObjectRemoved is not None:\n",
    "                        self.onObjectRemoved(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cars_going_left(file: str, debug_mode=False, slow_motion=False) -> (int, float):\n",
    "    \"\"\"\n",
    "    Counts the number of cars moving left in a video file.\n",
    "\n",
    "    Parameters:\n",
    "        file: The file path to the video to be analyzed.\n",
    "\n",
    "    Optional Parameters:\n",
    "        debug: If True, displays additional information for troubleshooting purposes.\n",
    "        slow_motion: If True, plays back the video at a reduced speed for closer inspection.\n",
    "\n",
    "    Returns:\n",
    "        A pair consisting of the total count of left-moving cars and their frequency per minute.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize video capture\n",
    "    video = cv2.VideoCapture(file)\n",
    "    assert video.isOpened(), \"Failed to open the specified video file.\"\n",
    "\n",
    "    # Setup for detecting moving objects\n",
    "    background_subtractor = cv2.createBackgroundSubtractorKNN(detectShadows=True, history=10000, dist2Threshold=400)\n",
    "\n",
    "    # Initialize the object tracking system\n",
    "    object_tracker = Tracker()\n",
    "\n",
    "    # Prepare a debugging window if requested\n",
    "    if debug_mode:\n",
    "        cv2.namedWindow(\"Debugging Output\")\n",
    "\n",
    "    # Keep track of cars moving left\n",
    "    ids_cars_counted = set()\n",
    "\n",
    "    # Callback for when an object is no longer being tracked\n",
    "    def onObjectRemoved(obj):\n",
    "        if (obj.tracking_id not in ids_cars_counted \n",
    "            and obj.x_axis_direction() < -2 \n",
    "            and len(obj.location_history) > 80):\n",
    "\n",
    "            ids_cars_counted.add(obj.tracking_id)\n",
    "\n",
    "    object_tracker.onObjectRemoved = onObjectRemoved\n",
    "\n",
    "    # Main loop for frame processing\n",
    "    while True:\n",
    "        read_success, video_frame = video.read()\n",
    "\n",
    "        if not read_success:\n",
    "            break\n",
    "\n",
    "        # Apply Gaussian blur to smoothen the frame\n",
    "        blurred_image = cv2.GaussianBlur(video_frame, (5, 5), 0)\n",
    "\n",
    "        # Create a mask for foreground objects\n",
    "        foreground_mask = background_subtractor.apply(blurred_image)\n",
    "\n",
    "        # Clean up the mask to remove shadows\n",
    "        _, foreground_mask = cv2.threshold(foreground_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Further refine the mask to eliminate noise\n",
    "        morphological_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        foreground_mask = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, morphological_kernel, iterations=2)\n",
    "\n",
    "        # Identify potential cars using contours\n",
    "        video_contours, _ = cv2.findContours(foreground_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Eliminate contours that are too small or located in the top half of the frame\n",
    "        video_contours = [c for c in video_contours if cv2.contourArea(c) > minimun_area_contour and cv2.boundingRect(c)[1] > video_frame.shape[0] / 2]\n",
    "        video_contours = [cv2.convexHull(c) for c in video_contours]\n",
    "\n",
    "        # In debug mode, draw contours on the frame for visualization\n",
    "        if debug_mode:\n",
    "            cv2.drawContours(video_frame, video_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        # Inform the tracker about the detected contours\n",
    "        object_tracker.update(video_contours)\n",
    "\n",
    "        # If in debug mode, annotate the frame with tracking info\n",
    "        if debug_mode:\n",
    "            for obj in object_tracker.objects:\n",
    "                cv2.putText(video_frame, f\"Car #{obj.tracking_id}\", obj.centroid, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.circle(video_frame, obj.centroid, 2, (0, 0, 255), -1)\n",
    "        \n",
    "        \n",
    "        cv2.putText(video_frame, f'Total Leftward Cars: {len(ids_cars_counted)}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Debugging Output\", video_frame)\n",
    "\n",
    "        # Slow-motion playback if enabled\n",
    "        if slow_motion:\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        # Exit on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    # Cleanup on exit\n",
    "    if debug_mode:\n",
    "        cv2.destroyWindow(\"Debug View\")\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    # Calculate the final counts and rate\n",
    "    car_count = len(ids_cars_counted)\n",
    "    count_of_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames_per_second = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    duration_in_seconds = count_of_frames / frames_per_second\n",
    "    cars_x_minute = car_count / duration_in_seconds * 60\n",
    "\n",
    "    video.release()\n",
    "\n",
    "    return (car_count, cars_x_minute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j\\AppData\\Local\\Temp\\ipykernel_39688\\1381607723.py:56: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.centroid = (int(kalman_prediction[0]), int(kalman_prediction[1]))\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\"Traffic_Laramie_1.mp4\", \"Traffic_Laramie_2.mp4\"]\n",
    "table_data = [\n",
    "    [file, *count_cars_going_left(file)] for file in file_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                     </th><th style=\"text-align: right;\">  Total number of cars</th><th style=\"text-align: right;\">  Cars per minute</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Traffic_Laramie_1.mp4</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">          2.02338</td></tr>\n",
       "<tr><td>Traffic_Laramie_2.mp4</td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">          2.27101</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                     </th><th style=\"text-align: right;\">  Total number of cars</th><th style=\"text-align: right;\">  Cars per minute</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>Traffic_Laramie_1.mp4</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">          2.02338</td></tr>\\n<tr><td>Traffic_Laramie_2.mp4</td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">          2.27101</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = tabulate.tabulate(table_data, tablefmt='html', headers=[\"\", \"Total number of cars\", \"Cars per minute\"])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
